{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler,SequentialSampler\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertModel, DistilBertPreTrainedModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logit\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = (torch.cuda.device_count() > 0)\n",
    "MASK_IDX = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def platt_scale(outcome,probs):\n",
    "    logits = logit(probs)\n",
    "    logits = logits.reshape(-1,1)\n",
    "    log_reg = LogisticRegression(penalty='none', warm_start = True, solver = 'lbfgs' )\n",
    "    log_reg.fit(logits, outcome)\n",
    "    return log_reg.predict_proba(logits)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1.0 + torch.erf(x/math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confound_vector(ids, vocab_size, use_counts = False):\n",
    "    vec = torch.zeros(ids.shape[0],vocab_size)\n",
    "    ones = torch.ones_like(ids,dtype = torch.float)\n",
    "    if CUDA:\n",
    "        vec = vec.cuda()\n",
    "        ones = ones.cuda()\n",
    "        ids = ids.cuda()\n",
    "    vec.scatter_add_(1, ids,ones)\n",
    "    vec[:,1] = 0.0\n",
    "    if not use_counts:\n",
    "        vec = (vec != 0).float()\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ImageCausalModel(nn.Module):\n",
    "    \"\"\"The model itself.\"\"\"\n",
    "    def __init__(self, num_labels = 2,pretrained_model_names = \"resnet50\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.base_model = timm.create_model(pretrained_model_names,pretrained = True)\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # 因果推論用の追加レイヤー\n",
    "        self.classifier = nn.Linear(self.base_model.num_features, num_labels)\n",
    "        self.Q_cls = nn.ModuleDict()\n",
    "\n",
    "        # self.base_model.num_features は、事前学習済みの画像モデルからの特徴量サイズです。\n",
    "        input_size = self.base_model.num_features + self.num_labels\n",
    "\n",
    "        for T in range(2):\n",
    "            # ModuleDict keys have to be strings..\n",
    "            self.Q_cls['%d' % T] = nn.Sequential(\n",
    "                nn.Linear(input_size, 200),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(200, self.num_labels))\n",
    "        \n",
    "\n",
    "        self.g_cls = nn.Linear(input_size + self.num_labels, \n",
    "            self.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self,images, confounders, treatment, outcome = None):\n",
    "        features = self.base_model(images)\n",
    "\n",
    "        C = meke_confound_vector(confounds, self.num_labels)\n",
    "\n",
    "        inputs = torch.cat((features, C), dim =  1)\n",
    "        \n",
    "        g_logits = self.g_cls(inputs)\n",
    "        g = torch.sigmoid(g_logits)\n",
    "\n",
    "        if outcome is not None:\n",
    "            g_loss = CrossEntropyLoss(g_logits, treatment)\n",
    "\n",
    "            Q_logits_T0 = self.Q_cls['0'](inputs)\n",
    "            Q_logits_T1 = self.Q_cls['1'](inputs)\n",
    "\n",
    "            T0_indices = (treatment==0).nonzero(as_tuple = True)\n",
    "            T1_indices = (treatment==1).nonzero(as_tuple = True)\n",
    "\n",
    "            Q_loss_T0 = CrossEntropyLoss()(Q_logits_T0, outcome[T0_indices])\n",
    "            Q_loss_T1= CrossEntropyLoss()(Q_logits_T1, outcome[T1_indices])\n",
    "\n",
    "            Q_loss = Q_loss_T0 + Q_loss_T1\n",
    "\n",
    "            total_loss = g_loss + Q_loss\n",
    "            return g, Q_logits_T0, Q_logits_T1, total_loss\n",
    "        else:\n",
    "            return torch.sigmoid(Q_logits_T0), torch.sigmoid(Q_logits_T1),None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalImageModelWrapper:\n",
    "    def __init__(self, g_weight=1.0, Q_weight=0.1, mlm_weight=1.0, batch_size=32):\n",
    "        self.model = ImageCausalModel(num_labels=2, pretrained_model_names=\"resnet50\")\n",
    "        if CUDA:\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "        self.loss_weights = {\n",
    "            'g': g_weight,\n",
    "            'Q': Q_weight\n",
    "        }\n",
    "        self.batch_size = batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
