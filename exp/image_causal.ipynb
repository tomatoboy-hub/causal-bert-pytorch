{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler,SequentialSampler\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertModel, DistilBertPreTrainedModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logit\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = (torch.cuda.device_count() > 0)\n",
    "MASK_IDX = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def platt_scale(outcome,probs):\n",
    "    logits = logit(probs)\n",
    "    logits = logits.reshape(-1,1)\n",
    "    log_reg = LogisticRegression(penalty='none', warm_start = True, solver = 'lbfgs' )\n",
    "    log_reg.fit(logits, outcome)\n",
    "    return log_reg.predict_proba(logits)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1.0 + torch.erf(x/math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confound_vector(ids, vocab_size, use_counts = False):\n",
    "    vec = torch.zeros(ids.shape[0],vocab_size)\n",
    "    ones = torch.ones_like(ids,dtype = torch.float)\n",
    "    \n",
    "    if CUDA:\n",
    "        vec = vec.cuda()\n",
    "        ones = ones.cuda()\n",
    "        ids = ids.cuda()\n",
    "    vec[:,1] = 0.0\n",
    "    if not use_counts:\n",
    "        vec = (vec != 0).float()\n",
    "    return vec.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ImageCausalModel(nn.Module):\n",
    "    \"\"\"The model itself.\"\"\"\n",
    "    def __init__(self, num_labels = 2,pretrained_model_names = \"resnet50\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.base_model = timm.create_model(pretrained_model_names,pretrained = True)\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # 因果推論用の追加レイヤー\n",
    "        self.classifier = nn.Linear(self.base_model.num_features, num_labels)\n",
    "        self.Q_cls = nn.ModuleDict()\n",
    "\n",
    "        # self.base_model.num_features は、事前学習済みの画像モデルからの特徴量サイズです。\n",
    "        input_size = self.base_model.num_features + self.num_labels\n",
    "\n",
    "        for T in range(2):\n",
    "            # ModuleDict keys have to be strings..\n",
    "            self.Q_cls['%d' % T] = nn.Sequential(\n",
    "                nn.Linear(input_size, 200),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(200, self.num_labels))\n",
    "        \n",
    "\n",
    "        self.g_cls = nn.Linear(self.base_model.num_features + self.num_labels, \n",
    "            self.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self,images, confounds, treatment=None, outcome = None):\n",
    "        features = self.base_model(images)\n",
    "        # print(\"features\")\n",
    "        # print(\"C\", confounds.shape)\n",
    "        # print(confounds)\n",
    "        # print(confounds.unsqueeze(1).shape)\n",
    "        C = make_confound_vector(confounds.unsqueeze(1), self.num_labels)\n",
    "        # print(\"C\",C.shape)  \n",
    "        print(features.shape)\n",
    "        print(confounds.shape)\n",
    "        print(confounds.unsqueeze(1))\n",
    "        print(confounds.unsqueeze(1).shape)\n",
    "        inputs = torch.cat((features, C), dim =  1)\n",
    "\n",
    "        print(inputs.shape)\n",
    "        g_logits = self.g_cls(inputs)\n",
    "        g_prob = torch.sigmoid(g_logits)\n",
    "\n",
    "        Q_logits_T0 = self.Q_cls['0'](inputs)\n",
    "        Q_logits_T1 = self.Q_cls['1'](inputs)\n",
    "\n",
    "        Q_prob_T0 = torch.sigmoid(Q_logits_T0)\n",
    "        Q_prob_T1 = torch.sigmoid(Q_logits_T1)\n",
    "        if outcome is not None:\n",
    "            return g_prob, Q_prob_T0, Q_prob_T1, g_logits, Q_logits_T0, Q_logits_T1\n",
    "        else:\n",
    "            return g_prob, Q_prob_T0, Q_prob_T1,\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalImageModelWrapper:\n",
    "    def __init__(self, g_weight=1.0, Q_weight=0.1, mlm_weight=1.0, batch_size=32):\n",
    "        self.model = ImageCausalModel(num_labels=2, pretrained_model_names=\"resnet50\")\n",
    "        if CUDA:\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "        self.loss_weights = {\n",
    "            'g': g_weight,\n",
    "            'Q': Q_weight\n",
    "        }\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train(self,images, confounds, treatments, outcomes , learning_rate = 2e-5, epochs  = 3):\n",
    "        dataloader = self.build_dataloader(images, confounds, treatments, outcomes, batch_size = self.batch_size)\n",
    "        self.model.train()\n",
    "        optimizer = AdamW(self.model.parameters(), lr = learning_rate, eps = 1e-8)\n",
    "        total_steps = len(dataloader) * epochs\n",
    "        warmup_steps = total_steps * 0.1\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = warmup_steps,num_training_steps = total_steps)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            for batch in dataloader:\n",
    "                if CUDA:\n",
    "                    batch = tuple(x.cuda() for x in batch)\n",
    "                images, confounds, treatments, outcomes = batch\n",
    "\n",
    "                self.model.zero_grad()\n",
    "                g_prob, Q_prob_T0, Q_prob_T1, g_logits, Q_logits_T0, Q_logits_T1 = self.model(images, confounds, treatments, outcomes)\n",
    "                g_loss = CrossEntropyLoss()(g_logits, treatments)\n",
    "                Q_loss_T0 = CrossEntropyLoss()(Q_logits_T0, outcomes)\n",
    "                Q_loss_T1 = CrossEntropyLoss()(Q_logits_T1, outcomes)\n",
    "\n",
    "                loss = self.loss_weights['g'] * g_loss + self.loss_weights['Q'] * (Q_loss_T0 + Q_loss_T1)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                losses.append(loss.detach().cpu().item())\n",
    "            \n",
    "        return self.model\n",
    "    \n",
    "    def inference(self, images, confounds, outcome = None):\n",
    "        self.model.eval()\n",
    "        dataloader = self.build_dataloader(images, confounds,outcomes = outcome,\n",
    "                                           sampler = 'sequential')\n",
    "        Q0s = []\n",
    "        Q1s = []\n",
    "        Ys = []\n",
    "        for i, batch in tqdm(enumerate(dataloader),total = len(dataloader)):\n",
    "            if CUDA: \n",
    "                batch = (x.cuda() for x in batch)\n",
    "            images, confounds, outcomes = batch\n",
    "            g_prob, Q0, Q1 = self.model(images, confounds, outcomes = outcomes)\n",
    "            Q0s += Q0.detach().cpu().numpy().tolist()\n",
    "            Q1s += Q1.detach().cpu().numpy().tolist()\n",
    "            Ys += outcomes.detach().cpu().numpy().tolist()\n",
    "\n",
    "            ## [todo] inferenceメソッドの形式?\n",
    "        probs = np.array(list(zip(Q0s, Q1s)))\n",
    "        preds = np.argmax(probs, axis = 1)    \n",
    "        return probs, preds,Ys\n",
    "    \n",
    "    def ATE(self,C,image, Y = None, platt_scaling = False):\n",
    "        ## [todo] ATEの計算方法\n",
    "        Q_probs,_,Ys = self.inference(image,C,outcome = Y)\n",
    "        if platt_scaling and Y is not None:\n",
    "            Q0 = platt_scale(Ys, Q_probs[:,0])[:,0]\n",
    "            Q1 = platt_scale(Ys, Q_probs[:,1])[:,1]\n",
    "        else:\n",
    "            Q0 = Q_probs[:,0]\n",
    "            Q1 = Q_probs[:,1]\n",
    "        return np.mean(Q0 - Q1)\n",
    "\n",
    "    def build_dataloader(self,image_paths, confounds, treatments = None, outcomes = None,batch_size = 32):\n",
    "        dataset = CausalImageDataset(image_paths, confounds, treatments, outcomes)\n",
    "        sampler = RandomSampler(dataset) if treatments is not None else SequentialSampler(dataset)\n",
    "        dataloader = DataLoader(dataset, batch_size = batch_size,sampler = sampler)\n",
    "        return dataloader\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalImageDataset(Dataset):\n",
    "    def __init__(self,image_paths, confounds, treatments = None, outcomes = None,transform = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.confounds = confounds\n",
    "        self.treatments = treatments\n",
    "        self.outcomes = outcomes\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406] , std = [0.229, 0.224, 0.225])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        confounds = self.confounds[idx]\n",
    "        treatment = self.treatments[idx] if self.treatments is not None else -1\n",
    "        outcome = self.outcomes[idx] if self.outcomes is not None else -1\n",
    "        return image , confounds, treatment, outcome\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>img_path</th>\n",
       "      <th>actual_price_yen</th>\n",
       "      <th>embedding_path</th>\n",
       "      <th>embedding</th>\n",
       "      <th>price_ave</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>AmazonBasics High Speed 55 Watt Oscillating Pe...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QfUcEOg8...</td>\n",
       "      <td>https://www.amazon.in/AmazonBasics-400mm-Pedes...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6113</td>\n",
       "      <td>₹2,099</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>363000.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>29.492722</td>\n",
       "      <td>1</td>\n",
       "      <td>1863.892722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Farberware Mini Blender Fruit Mixer Machine Po...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716mmFt0PG...</td>\n",
       "      <td>https://www.amazon.in/Farberware-Portable-Elec...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6071</td>\n",
       "      <td>₹499</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>131890.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>68.038506</td>\n",
       "      <td>0</td>\n",
       "      <td>1889.338506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>PHILIPS Handheld Garment Steamer STH3000/20 - ...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71W2XPQdBq...</td>\n",
       "      <td>https://www.amazon.in/PHILIPS-Handheld-Garment...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1553</td>\n",
       "      <td>₹3,995</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>450450.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>43.871647</td>\n",
       "      <td>1</td>\n",
       "      <td>510.271647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>Cookwell Bullet Mixer Grinder (5 Jars, 3 Blade...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81yobRRV8n...</td>\n",
       "      <td>https://www.amazon.in/Cookwell-Bullet-Mixer-Gr...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9592</td>\n",
       "      <td>₹2,479</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>660000.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>45.319656</td>\n",
       "      <td>1</td>\n",
       "      <td>2923.419656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>Bajaj ATX 4 750-Watt Pop-up Toaster, 2-Slice A...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51D5T7TGVb...</td>\n",
       "      <td>https://www.amazon.in/Bajaj-ATX-750-Watt-Pop-u...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9520</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>51.195602</td>\n",
       "      <td>0</td>\n",
       "      <td>2907.195602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0          72   \n",
       "1             1          73   \n",
       "2             2          74   \n",
       "3             3          75   \n",
       "4             4          76   \n",
       "\n",
       "                                                name main_category  \\\n",
       "0  AmazonBasics High Speed 55 Watt Oscillating Pe...    appliances   \n",
       "1  Farberware Mini Blender Fruit Mixer Machine Po...    appliances   \n",
       "2  PHILIPS Handheld Garment Steamer STH3000/20 - ...    appliances   \n",
       "3  Cookwell Bullet Mixer Grinder (5 Jars, 3 Blade...    appliances   \n",
       "4  Bajaj ATX 4 750-Watt Pop-up Toaster, 2-Slice A...    appliances   \n",
       "\n",
       "     sub_category                                              image  \\\n",
       "0  All Appliances  https://m.media-amazon.com/images/I/71QfUcEOg8...   \n",
       "1  All Appliances  https://m.media-amazon.com/images/I/716mmFt0PG...   \n",
       "2  All Appliances  https://m.media-amazon.com/images/I/71W2XPQdBq...   \n",
       "3  All Appliances  https://m.media-amazon.com/images/I/81yobRRV8n...   \n",
       "4  All Appliances  https://m.media-amazon.com/images/I/51D5T7TGVb...   \n",
       "\n",
       "                                                link ratings  no_of_ratings  \\\n",
       "0  https://www.amazon.in/AmazonBasics-400mm-Pedes...     4.1           6113   \n",
       "1  https://www.amazon.in/Farberware-Portable-Elec...     2.9           6071   \n",
       "2  https://www.amazon.in/PHILIPS-Handheld-Garment...     4.0           1553   \n",
       "3  https://www.amazon.in/Cookwell-Bullet-Mixer-Gr...     4.1           9592   \n",
       "4  https://www.amazon.in/Bajaj-ATX-750-Watt-Pop-u...     4.3           9520   \n",
       "\n",
       "  discount_price  actual_price  \\\n",
       "0         ₹2,099        3300.0   \n",
       "1           ₹499        1199.0   \n",
       "2         ₹3,995        4095.0   \n",
       "3         ₹2,479        6000.0   \n",
       "4         ₹1,499        2250.0   \n",
       "\n",
       "                                            img_path  actual_price_yen  \\\n",
       "0  /root/graduation_thetis/causal-bert-pytorch/in...          363000.0   \n",
       "1  /root/graduation_thetis/causal-bert-pytorch/in...          131890.0   \n",
       "2  /root/graduation_thetis/causal-bert-pytorch/in...          450450.0   \n",
       "3  /root/graduation_thetis/causal-bert-pytorch/in...          660000.0   \n",
       "4  /root/graduation_thetis/causal-bert-pytorch/in...          247500.0   \n",
       "\n",
       "                                      embedding_path  embedding  price_ave  \\\n",
       "0  /root/graduation_thetis/causal-bert-pytorch/in...  29.492722          1   \n",
       "1  /root/graduation_thetis/causal-bert-pytorch/in...  68.038506          0   \n",
       "2  /root/graduation_thetis/causal-bert-pytorch/in...  43.871647          1   \n",
       "3  /root/graduation_thetis/causal-bert-pytorch/in...  45.319656          1   \n",
       "4  /root/graduation_thetis/causal-bert-pytorch/in...  51.195602          0   \n",
       "\n",
       "        output  \n",
       "0  1863.892722  \n",
       "1  1889.338506  \n",
       "2   510.271647  \n",
       "3  2923.419656  \n",
       "4  2907.195602  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\")\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/outputs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5111,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/outputs_v2.csv\")\n",
    "print(df[\"no_of_ratings\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>img_path</th>\n",
       "      <th>actual_price_yen</th>\n",
       "      <th>embedding_path</th>\n",
       "      <th>embedding</th>\n",
       "      <th>price_ave</th>\n",
       "      <th>output</th>\n",
       "      <th>output_2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>AmazonBasics High Speed 55 Watt Oscillating Pe...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QfUcEOg8...</td>\n",
       "      <td>https://www.amazon.in/AmazonBasics-400mm-Pedes...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6113</td>\n",
       "      <td>₹2,099</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>363000.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>29.492722</td>\n",
       "      <td>1</td>\n",
       "      <td>1863.892722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Farberware Mini Blender Fruit Mixer Machine Po...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716mmFt0PG...</td>\n",
       "      <td>https://www.amazon.in/Farberware-Portable-Elec...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6071</td>\n",
       "      <td>₹499</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>131890.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>68.038506</td>\n",
       "      <td>0</td>\n",
       "      <td>1889.338506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>PHILIPS Handheld Garment Steamer STH3000/20 - ...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71W2XPQdBq...</td>\n",
       "      <td>https://www.amazon.in/PHILIPS-Handheld-Garment...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1553</td>\n",
       "      <td>₹3,995</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>450450.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>43.871647</td>\n",
       "      <td>1</td>\n",
       "      <td>510.271647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>Cookwell Bullet Mixer Grinder (5 Jars, 3 Blade...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81yobRRV8n...</td>\n",
       "      <td>https://www.amazon.in/Cookwell-Bullet-Mixer-Gr...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9592</td>\n",
       "      <td>₹2,479</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>660000.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>45.319656</td>\n",
       "      <td>1</td>\n",
       "      <td>2923.419656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>Bajaj ATX 4 750-Watt Pop-up Toaster, 2-Slice A...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51D5T7TGVb...</td>\n",
       "      <td>https://www.amazon.in/Bajaj-ATX-750-Watt-Pop-u...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9520</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>51.195602</td>\n",
       "      <td>0</td>\n",
       "      <td>2907.195602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0             0          72   \n",
       "1             1             1          73   \n",
       "2             2             2          74   \n",
       "3             3             3          75   \n",
       "4             4             4          76   \n",
       "\n",
       "                                                name main_category  \\\n",
       "0  AmazonBasics High Speed 55 Watt Oscillating Pe...    appliances   \n",
       "1  Farberware Mini Blender Fruit Mixer Machine Po...    appliances   \n",
       "2  PHILIPS Handheld Garment Steamer STH3000/20 - ...    appliances   \n",
       "3  Cookwell Bullet Mixer Grinder (5 Jars, 3 Blade...    appliances   \n",
       "4  Bajaj ATX 4 750-Watt Pop-up Toaster, 2-Slice A...    appliances   \n",
       "\n",
       "     sub_category                                              image  \\\n",
       "0  All Appliances  https://m.media-amazon.com/images/I/71QfUcEOg8...   \n",
       "1  All Appliances  https://m.media-amazon.com/images/I/716mmFt0PG...   \n",
       "2  All Appliances  https://m.media-amazon.com/images/I/71W2XPQdBq...   \n",
       "3  All Appliances  https://m.media-amazon.com/images/I/81yobRRV8n...   \n",
       "4  All Appliances  https://m.media-amazon.com/images/I/51D5T7TGVb...   \n",
       "\n",
       "                                                link ratings  no_of_ratings  \\\n",
       "0  https://www.amazon.in/AmazonBasics-400mm-Pedes...     4.1           6113   \n",
       "1  https://www.amazon.in/Farberware-Portable-Elec...     2.9           6071   \n",
       "2  https://www.amazon.in/PHILIPS-Handheld-Garment...     4.0           1553   \n",
       "3  https://www.amazon.in/Cookwell-Bullet-Mixer-Gr...     4.1           9592   \n",
       "4  https://www.amazon.in/Bajaj-ATX-750-Watt-Pop-u...     4.3           9520   \n",
       "\n",
       "  discount_price  actual_price  \\\n",
       "0         ₹2,099        3300.0   \n",
       "1           ₹499        1199.0   \n",
       "2         ₹3,995        4095.0   \n",
       "3         ₹2,479        6000.0   \n",
       "4         ₹1,499        2250.0   \n",
       "\n",
       "                                            img_path  actual_price_yen  \\\n",
       "0  /root/graduation_thetis/causal-bert-pytorch/in...          363000.0   \n",
       "1  /root/graduation_thetis/causal-bert-pytorch/in...          131890.0   \n",
       "2  /root/graduation_thetis/causal-bert-pytorch/in...          450450.0   \n",
       "3  /root/graduation_thetis/causal-bert-pytorch/in...          660000.0   \n",
       "4  /root/graduation_thetis/causal-bert-pytorch/in...          247500.0   \n",
       "\n",
       "                                      embedding_path  embedding  price_ave  \\\n",
       "0  /root/graduation_thetis/causal-bert-pytorch/in...  29.492722          1   \n",
       "1  /root/graduation_thetis/causal-bert-pytorch/in...  68.038506          0   \n",
       "2  /root/graduation_thetis/causal-bert-pytorch/in...  43.871647          1   \n",
       "3  /root/graduation_thetis/causal-bert-pytorch/in...  45.319656          1   \n",
       "4  /root/graduation_thetis/causal-bert-pytorch/in...  51.195602          0   \n",
       "\n",
       "        output  output_2v  \n",
       "0  1863.892722          1  \n",
       "1  1889.338506          1  \n",
       "2   510.271647          1  \n",
       "3  2923.419656          1  \n",
       "4  2907.195602          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 97],\n",
      "        [251]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[57],\n",
      "        [ 7]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[102],\n",
      "        [  7]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[660],\n",
      "        [ 43]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[81],\n",
      "        [23]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[689],\n",
      "        [282]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[83],\n",
      "        [10]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 332],\n",
      "        [2090]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[4314],\n",
      "        [ 110]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 113],\n",
      "        [1734]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[2013],\n",
      "        [  15]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  3],\n",
      "        [821]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[189],\n",
      "        [  4]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[1770],\n",
      "        [   1]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[25],\n",
      "        [54]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 14],\n",
      "        [123]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[142],\n",
      "        [  2]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[1046],\n",
      "        [3495]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[296],\n",
      "        [ 18]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[281],\n",
      "        [202]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[203],\n",
      "        [636]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 22],\n",
      "        [435]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  15],\n",
      "        [1588]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[5314],\n",
      "        [1774]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[555],\n",
      "        [168]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[276],\n",
      "        [ 52]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[22],\n",
      "        [30]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[976],\n",
      "        [ 39]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[169],\n",
      "        [ 19]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[58],\n",
      "        [ 3]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[1248],\n",
      "        [3237]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 113],\n",
      "        [2629]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[580],\n",
      "        [323]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[909],\n",
      "        [  6]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 63],\n",
      "        [646]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[3123],\n",
      "        [ 340]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[137],\n",
      "        [102]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[150],\n",
      "        [777]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[570],\n",
      "        [ 50]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[77],\n",
      "        [ 9]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[106],\n",
      "        [  5]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[1154],\n",
      "        [6218]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  1],\n",
      "        [144]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 31],\n",
      "        [342]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[24],\n",
      "        [ 4]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[174],\n",
      "        [  9]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 6],\n",
      "        [61]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[5045],\n",
      "        [ 403]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[10],\n",
      "        [60]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 38],\n",
      "        [916]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[2195],\n",
      "        [   3]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  78],\n",
      "        [4784]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  50],\n",
      "        [3036]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[488],\n",
      "        [  1]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[356],\n",
      "        [  2]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  55],\n",
      "        [2396]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[2379],\n",
      "        [ 789]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 2],\n",
      "        [57]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[   3],\n",
      "        [4590]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[403],\n",
      "        [640]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[18],\n",
      "        [ 9]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 71],\n",
      "        [348]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[   4],\n",
      "        [6071]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[   1],\n",
      "        [1211]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[683],\n",
      "        [ 37]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[235],\n",
      "        [ 44]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[   6],\n",
      "        [1200]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[30],\n",
      "        [ 4]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  43],\n",
      "        [8693]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 31],\n",
      "        [387]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[67],\n",
      "        [40]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[   41],\n",
      "        [22369]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[100],\n",
      "        [ 58]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 9],\n",
      "        [40]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 162],\n",
      "        [1266]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 831],\n",
      "        [2619]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[377],\n",
      "        [  6]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[73],\n",
      "        [78]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[6548],\n",
      "        [  13]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[61],\n",
      "        [16]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 3],\n",
      "        [52]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 7],\n",
      "        [11]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[2],\n",
      "        [1]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[2748],\n",
      "        [ 311]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 589],\n",
      "        [1520]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[179],\n",
      "        [ 39]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[24],\n",
      "        [ 8]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[58],\n",
      "        [57]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 1467],\n",
      "        [13467]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 890],\n",
      "        [9338]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[602],\n",
      "        [  6]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[125],\n",
      "        [ 31]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[ 732],\n",
      "        [9875]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[43],\n",
      "        [ 1]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[  44],\n",
      "        [1311]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[62],\n",
      "        [63]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n",
      "vec_ones\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.],\n",
      "        [1.]], device='cuda:0')\n",
      "scatter_add_\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "torch.Size([2, 2048])\n",
      "torch.Size([2])\n",
      "tensor([[6755],\n",
      "        [   1]], device='cuda:0')\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 2050])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ci \u001b[38;5;241m=\u001b[39m CausalImageModelWrapper(batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, g_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, Q_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno_of_ratings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprice_ave\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_2v\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(ci\u001b[38;5;241m.\u001b[39mATE(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_ave\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], platt_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36mCausalImageModelWrapper.train\u001b[0;34m(self, images, confounds, treatments, outcomes, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m images, confounds, treatments, outcomes \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m g_prob, Q_prob_T0, Q_prob_T1, g_logits, Q_logits_T0, Q_logits_T1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreatments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcomes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()(g_logits, treatments)\n\u001b[1;32m     31\u001b[0m Q_loss_T0 \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()(Q_logits_T0, outcomes)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mImageCausalModel.forward\u001b[0;34m(self, images, confounds, treatment, outcome)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,images, confounds, treatment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, outcome \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# print(\"features\")\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# print(\"C\", confounds.shape)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# print(confounds)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# print(confounds.unsqueeze(1).shape)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     C \u001b[38;5;241m=\u001b[39m make_confound_vector(confounds\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/timm/models/resnet.py:635\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 635\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/timm/models/resnet.py:624\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    622\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    623\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 624\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/timm/models/resnet.py:211\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m    210\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m--> 211\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m    214\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:104\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/functional.py:1498\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ci = CausalImageModelWrapper(batch_size = 2, g_weight=0.1, Q_weight=0.1)\n",
    "ci.train(df[\"img_path\"],df[\"no_of_ratings\"], df[\"price_ave\"], df[\"output_2v\"],epochs = 1)\n",
    "print(ci.ATE(df[\"price_ave\"], df[\"img_path\"], platt_scaling = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
