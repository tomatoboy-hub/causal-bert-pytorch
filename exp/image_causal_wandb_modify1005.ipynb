{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler,SequentialSampler\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logit\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wandbの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhayatarou-ay\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = (torch.cuda.device_count() > 0)\n",
    "MASK_IDX = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def platt_scale(outcome,probs):\n",
    "    logits = logit(probs)\n",
    "    logits = logits.reshape(-1,1)\n",
    "    log_reg = LogisticRegression(penalty='none', warm_start = True, solver = 'lbfgs' )\n",
    "    log_reg.fit(logits, outcome)\n",
    "    return log_reg.predict_proba(logits)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1.0 + torch.erf(x/math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confound_vector(ids, vocab_size, use_counts = False):\n",
    "    vec = torch.zeros(ids.shape[0],vocab_size)\n",
    "    ones = torch.ones_like(ids,dtype = torch.float)\n",
    "    \n",
    "    if CUDA:\n",
    "        vec = vec.cuda()\n",
    "        ones = ones.cuda()\n",
    "        ids = ids.cuda()\n",
    "    vec[:,1] = 0.0\n",
    "    if not use_counts:\n",
    "        vec = (vec != 0).float()\n",
    "    return vec.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ImageCausalModel(nn.Module):\n",
    "    \"\"\"The model itself.\"\"\"\n",
    "    def __init__(self, num_labels = 2,pretrained_model_names = \"timm/eva02_base_patch14_224.mim_in22k\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.base_model = timm.create_model(pretrained_model_names,pretrained = True,num_classes = 0)\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # 因果推論用の追加レイヤー ここいらない説\n",
    "        #self.classifier = nn.Linear(self.base_model.num_features, num_labels)\n",
    "        self.Q_cls = nn.ModuleDict()\n",
    "\n",
    "        # self.base_model.num_features は、事前学習済みの画像モデルからの特徴量サイズです。\n",
    "        input_size = self.base_model.num_features + self.num_labels\n",
    "        print(self.base_model.num_features)\n",
    "        print(input_size)\n",
    "        for T in range(2):\n",
    "            # ModuleDict keys have to be strings..\n",
    "            self.Q_cls['%d' % T] = nn.Sequential(\n",
    "                nn.Linear(input_size, 200),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(200, self.num_labels))\n",
    "        \n",
    "\n",
    "        self.g_cls = nn.Linear(self.base_model.num_features + self.num_labels, \n",
    "            self.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self,images, confounds, treatment=None, outcome = None):\n",
    "        features = self.base_model(images)\n",
    "        # print(\"features\")\n",
    "        # print(\"C\", confounds.shape)\n",
    "        # print(confounds)\n",
    "        # print(confounds.unsqueeze(1).shape)\n",
    "        C = make_confound_vector(confounds.unsqueeze(1), self.num_labels)\n",
    "        inputs = torch.cat((features, C), dim =  1)\n",
    "        g = self.g_cls(inputs)\n",
    "\n",
    "        if outcome is not None:\n",
    "            g_loss = CrossEntropyLoss()(g.view(-1, self.num_labels),treatment.view(-1))\n",
    "        else:\n",
    "            g_loss = 0.0\n",
    "\n",
    "        Q_logits_T0 = self.Q_cls['0'](inputs)\n",
    "        Q_logits_T1 = self.Q_cls['1'](inputs)\n",
    "        print(Q_logits_T0)\n",
    "        print(Q_logits_T1)\n",
    "\n",
    "        #[todo] ここ元論文と実装が異なってたなぜ?\n",
    "        #Q_prob_T0 = torch.sigmoid(Q_logits_T0)\n",
    "        #Q_prob_T1 = torch.sigmoid(Q_logits_T1)\n",
    "        if outcome is not None:\n",
    "            T0_indices = (treatment == 0).nonzero().squeeze()\n",
    "            Y_T1_labels = outcome.clone().scatter(0,T0_indices, -100)\n",
    "\n",
    "            T1_indices = (treatment == 1).nonzero().squeeze()\n",
    "            Y_T0_labels = outcome.clone().scatter(0,T1_indices, -100)\n",
    "            Q_loss_T1 = CrossEntropyLoss()(Q_logits_T1.view(-1,self.num_labels), Y_T1_labels)\n",
    "            Q_loss_T0 = CrossEntropyLoss()(Q_logits_T0.view(-1, self.num_labels), Y_T0_labels)\n",
    "            Q_loss = Q_loss_T1 + Q_loss_T0\n",
    "        else:\n",
    "            Q_loss = 0.0\n",
    "            \n",
    "        sm = torch.nn.Softmax(dim = 1)\n",
    "        Q_prob_T0 = sm(Q_logits_T0)[:,1]\n",
    "        Q_prob_T1 = sm(Q_logits_T1)[:,1]\n",
    "        g_prob = sm(g)[:,1]\n",
    "        \n",
    "        return g_prob, Q_prob_T0, Q_prob_T1, g_loss, Q_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CausalImageModelWrapper:\n",
    "    def __init__(self, g_weight=1.0, Q_weight=0.1, mlm_weight=1.0, batch_size=32):\n",
    "        self.model = ImageCausalModel(num_labels=2, pretrained_model_names=\"timm/eva02_tiny_patch14_224.mim_in22k\")\n",
    "        if CUDA:\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "        self.loss_weights = {\n",
    "            'g': g_weight,\n",
    "            'Q': Q_weight\n",
    "        }\n",
    "        self.batch_size = batch_size\n",
    "        self.losses = []\n",
    "\n",
    "    def train(self,images, confounds, treatments, outcomes , learning_rate = 2e-5, epochs  = 3):\n",
    "\n",
    "        wandb.init(project = \"image_causal_project\", config = {\n",
    "            \"learning_rate\":learning_rate,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"g_weight\": self.loss_weights['g'],\n",
    "            \"Q_weight\": self.loss_weights['Q']\n",
    "        })\n",
    "\n",
    "        dataloader = self.build_dataloader(images, confounds, treatments, outcomes, batch_size = self.batch_size)\n",
    "        self.model.train()\n",
    "        optimizer = AdamW(self.model.parameters(), lr = learning_rate, eps = 1e-8)\n",
    "        total_steps = len(dataloader) * epochs\n",
    "        warmup_steps = total_steps * 0.1\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = warmup_steps,num_training_steps = total_steps)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "            g_losses = []\n",
    "            Q_losses = []\n",
    "            self.model.train()\n",
    "            for batch in dataloader:\n",
    "                if CUDA:\n",
    "                    batch = tuple(x.cuda() for x in batch)\n",
    "                images, confounds, treatments, outcomes = batch\n",
    "\n",
    "                self.model.zero_grad()\n",
    "                g, Q0, Q1, g_loss, Q_loss = self.model(images, confounds, treatments, outcomes)\n",
    "                loss = self.loss_weights['g'] * g_loss + self.loss_weights['Q'] * (Q_loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                g_losses.append(g_loss.detach().cpu().item())\n",
    "                Q_losses.append((Q_loss).detach().cpu().item())\n",
    "                epoch_losses.append(loss.detach().cpu().item())\n",
    "            \n",
    "            avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            avg_g_loss = sum(g_losses) / len(g_losses)\n",
    "            avg_Q_loss = sum(Q_losses) / len(Q_losses)\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch, \n",
    "                \"loss\":avg_loss, \n",
    "                \"g_losses\":avg_g_loss, \n",
    "                \"Q_losses\" : avg_Q_loss\n",
    "                })\n",
    "        wandb.watch(self.model)\n",
    "        wandb.finish()            \n",
    "        return self.model\n",
    "    \n",
    "    def inference(self, images, confounds, outcome = None):\n",
    "        self.model.eval()\n",
    "        dataloader = self.build_dataloader(images, confounds,outcomes = outcome,\n",
    "                                           sampler = 'sequential')\n",
    "        Q0s = []\n",
    "        Q1s = []\n",
    "        Ys = []\n",
    "        for i, batch in tqdm(enumerate(dataloader),total = len(dataloader)):\n",
    "            if CUDA: \n",
    "                batch = (x.cuda() for x in batch)\n",
    "            images, confounds, _ ,outcomes = batch\n",
    "\n",
    "            g, Q0,Q1,_,_= self.model(images, confounds, outcome = None)\n",
    "\n",
    "            Q0s += Q0.detach().cpu().numpy().tolist()\n",
    "            Q1s += Q1.detach().cpu().numpy().tolist()\n",
    "            Ys += outcomes.detach().cpu().numpy().tolist()\n",
    "\n",
    "            ## [todo] inferenceメソッドの形式?\n",
    "        print(len(Q0s), len(Q1s))\n",
    "        probs = np.array(list(zip(Q0s, Q1s)))\n",
    "        preds = np.argmax(probs, axis = 1)  \n",
    "\n",
    "        return probs, preds, Ys\n",
    "    \n",
    "    def ATE(self,C,image, Y = None, platt_scaling = False):\n",
    "        ## [todo] ATEの計算方法\n",
    "        Q_probs,_,Ys = self.inference(image,C,outcome = Y)\n",
    "        if platt_scaling and Y is not None:\n",
    "            Q0 = platt_scale(Ys, Q_probs[:,0])[:,0]\n",
    "            Q1 = platt_scale(Ys, Q_probs[:,1])[:,1]\n",
    "        else:\n",
    "            Q0 = Q_probs[:,0]\n",
    "            Q1 = Q_probs[:,1]\n",
    "        \n",
    "        print(\"Q0:\", Q0, \"Q1:\", Q1)\n",
    "        return np.mean(Q0 - Q1)\n",
    "\n",
    "    def build_dataloader(self,image_paths, confounds, treatments = None, outcomes = None,batch_size = 32,sampler = \"random\"):\n",
    "        dataset = CausalImageDataset(image_paths, confounds, treatments, outcomes)\n",
    "        sampler = RandomSampler(dataset) if sampler == \"random\" else SequentialSampler(dataset)\n",
    "        dataloader = DataLoader(dataset, batch_size = batch_size,sampler = sampler)\n",
    "        return dataloader\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalImageDataset(Dataset):\n",
    "    def __init__(self,image_paths, confounds, treatments = None, outcomes = None,transform = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.confounds = confounds\n",
    "        self.treatments = treatments\n",
    "        self.outcomes = outcomes\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406] , std = [0.229, 0.224, 0.225])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        confounds = self.confounds[idx]\n",
    "        treatment = self.treatments[idx] if self.treatments is not None else -1\n",
    "        outcome = self.outcomes[idx] if self.outcomes is not None else -1\n",
    "        return image , confounds, treatment, outcome\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_path</th>\n",
       "      <th>embedding</th>\n",
       "      <th>price_ave</th>\n",
       "      <th>output</th>\n",
       "      <th>output_2v</th>\n",
       "      <th>brightness</th>\n",
       "      <th>light_or_dark</th>\n",
       "      <th>outcome</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>AmazonBasics High Speed 55 Watt Oscillating Pe...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QfUcEOg8...</td>\n",
       "      <td>https://www.amazon.in/AmazonBasics-400mm-Pedes...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6113</td>\n",
       "      <td>...</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>29.492722</td>\n",
       "      <td>1</td>\n",
       "      <td>1863.892722</td>\n",
       "      <td>1</td>\n",
       "      <td>191.928625</td>\n",
       "      <td>light</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768525</td>\n",
       "      <td>0.645656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Farberware Mini Blender Fruit Mixer Machine Po...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/716mmFt0PG...</td>\n",
       "      <td>https://www.amazon.in/Farberware-Portable-Elec...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6071</td>\n",
       "      <td>...</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>68.038506</td>\n",
       "      <td>0</td>\n",
       "      <td>1889.338506</td>\n",
       "      <td>1</td>\n",
       "      <td>199.540718</td>\n",
       "      <td>light</td>\n",
       "      <td>0</td>\n",
       "      <td>0.768525</td>\n",
       "      <td>0.645656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>PHILIPS Handheld Garment Steamer STH3000/20 - ...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71W2XPQdBq...</td>\n",
       "      <td>https://www.amazon.in/PHILIPS-Handheld-Garment...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1553</td>\n",
       "      <td>...</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>43.871647</td>\n",
       "      <td>1</td>\n",
       "      <td>510.271647</td>\n",
       "      <td>1</td>\n",
       "      <td>199.711660</td>\n",
       "      <td>light</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768525</td>\n",
       "      <td>0.645656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>Cookwell Bullet Mixer Grinder (5 Jars, 3 Blade...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81yobRRV8n...</td>\n",
       "      <td>https://www.amazon.in/Cookwell-Bullet-Mixer-Gr...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9592</td>\n",
       "      <td>...</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>45.319656</td>\n",
       "      <td>1</td>\n",
       "      <td>2923.419656</td>\n",
       "      <td>1</td>\n",
       "      <td>206.265611</td>\n",
       "      <td>light</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768525</td>\n",
       "      <td>0.645656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>Bajaj ATX 4 750-Watt Pop-up Toaster, 2-Slice A...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>All Appliances</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51D5T7TGVb...</td>\n",
       "      <td>https://www.amazon.in/Bajaj-ATX-750-Watt-Pop-u...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9520</td>\n",
       "      <td>...</td>\n",
       "      <td>/root/graduation_thetis/causal-bert-pytorch/in...</td>\n",
       "      <td>51.195602</td>\n",
       "      <td>0</td>\n",
       "      <td>2907.195602</td>\n",
       "      <td>1</td>\n",
       "      <td>214.465127</td>\n",
       "      <td>light</td>\n",
       "      <td>1</td>\n",
       "      <td>0.768525</td>\n",
       "      <td>0.645656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0             0          72   \n",
       "1             1             1          73   \n",
       "2             2             2          74   \n",
       "3             3             3          75   \n",
       "4             4             4          76   \n",
       "\n",
       "                                                name main_category  \\\n",
       "0  AmazonBasics High Speed 55 Watt Oscillating Pe...    appliances   \n",
       "1  Farberware Mini Blender Fruit Mixer Machine Po...    appliances   \n",
       "2  PHILIPS Handheld Garment Steamer STH3000/20 - ...    appliances   \n",
       "3  Cookwell Bullet Mixer Grinder (5 Jars, 3 Blade...    appliances   \n",
       "4  Bajaj ATX 4 750-Watt Pop-up Toaster, 2-Slice A...    appliances   \n",
       "\n",
       "     sub_category                                              image  \\\n",
       "0  All Appliances  https://m.media-amazon.com/images/I/71QfUcEOg8...   \n",
       "1  All Appliances  https://m.media-amazon.com/images/I/716mmFt0PG...   \n",
       "2  All Appliances  https://m.media-amazon.com/images/I/71W2XPQdBq...   \n",
       "3  All Appliances  https://m.media-amazon.com/images/I/81yobRRV8n...   \n",
       "4  All Appliances  https://m.media-amazon.com/images/I/51D5T7TGVb...   \n",
       "\n",
       "                                                link ratings  no_of_ratings  \\\n",
       "0  https://www.amazon.in/AmazonBasics-400mm-Pedes...     4.1           6113   \n",
       "1  https://www.amazon.in/Farberware-Portable-Elec...     2.9           6071   \n",
       "2  https://www.amazon.in/PHILIPS-Handheld-Garment...     4.0           1553   \n",
       "3  https://www.amazon.in/Cookwell-Bullet-Mixer-Gr...     4.1           9592   \n",
       "4  https://www.amazon.in/Bajaj-ATX-750-Watt-Pop-u...     4.3           9520   \n",
       "\n",
       "   ...                                     embedding_path  embedding  \\\n",
       "0  ...  /root/graduation_thetis/causal-bert-pytorch/in...  29.492722   \n",
       "1  ...  /root/graduation_thetis/causal-bert-pytorch/in...  68.038506   \n",
       "2  ...  /root/graduation_thetis/causal-bert-pytorch/in...  43.871647   \n",
       "3  ...  /root/graduation_thetis/causal-bert-pytorch/in...  45.319656   \n",
       "4  ...  /root/graduation_thetis/causal-bert-pytorch/in...  51.195602   \n",
       "\n",
       "  price_ave       output output_2v  brightness  light_or_dark  outcome  \\\n",
       "0         1  1863.892722         1  191.928625          light        1   \n",
       "1         0  1889.338506         1  199.540718          light        0   \n",
       "2         1   510.271647         1  199.711660          light        1   \n",
       "3         1  2923.419656         1  206.265611          light        1   \n",
       "4         0  2907.195602         1  214.465127          light        1   \n",
       "\n",
       "         y0        y1  \n",
       "0  0.768525  0.645656  \n",
       "1  0.768525  0.645656  \n",
       "2  0.768525  0.645656  \n",
       "3  0.768525  0.645656  \n",
       "4  0.768525  0.645656  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\")\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/outputs_v4.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"light_or_dark\"] = df[\"light_or_dark\"].apply(lambda x : 1 if x == \"light\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/graduation_thetis/causal-bert-pytorch/exp/wandb/run-20241017_170701-5uimxhlj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hayatarou-ay/image_causal_project/runs/5uimxhlj' target=\"_blank\">sandy-galaxy-52</a></strong> to <a href='https://wandb.ai/hayatarou-ay/image_causal_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hayatarou-ay/image_causal_project' target=\"_blank\">https://wandb.ai/hayatarou-ay/image_causal_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hayatarou-ay/image_causal_project/runs/5uimxhlj' target=\"_blank\">https://wandb.ai/hayatarou-ay/image_causal_project/runs/5uimxhlj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4688, -3.0438],\n",
      "        [-2.4457, -3.8829]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.0572,  1.7502],\n",
      "        [ 0.3384,  1.7102]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6931, -3.8541],\n",
      "        [-1.0816, -2.8467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0441,  0.6811],\n",
      "        [-0.0090,  2.0738]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3349, -1.9912],\n",
      "        [-0.8975, -3.5203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6404,  0.1491],\n",
      "        [-0.4159,  1.3132]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.9503, -2.6957],\n",
      "        [-0.4770, -3.1406]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.8090,  2.9629],\n",
      "        [-0.7467,  0.4627]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0405, -2.8024],\n",
      "        [-0.2477, -3.7976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3136,  1.4673],\n",
      "        [-0.6989,  0.7855]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.0308, -3.6290],\n",
      "        [-0.5823, -3.4793]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1871,  0.5410],\n",
      "        [-0.6027,  1.1922]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.9611, -3.2849],\n",
      "        [-0.8798, -3.1518]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2348,  0.8154],\n",
      "        [-0.3005,  1.8274]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.8793, -1.8621],\n",
      "        [-1.2983, -3.8817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.9128,  4.0904],\n",
      "        [ 0.2745,  1.5652]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3572, -0.5628],\n",
      "        [-0.5572, -3.2643]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.7445,  3.0989],\n",
      "        [-1.3384,  1.0840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0047, -4.0127],\n",
      "        [-0.6244, -2.9933]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5027,  1.9272],\n",
      "        [-0.6392,  0.6655]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.1580, -1.6918],\n",
      "        [-1.5789, -2.4540]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.8534,  1.2799],\n",
      "        [-2.2215,  3.6461]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1516, -3.2534],\n",
      "        [-0.9172, -2.9446]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2603,  0.2568],\n",
      "        [-0.2198,  2.3961]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.4440, -2.7832],\n",
      "        [-1.2181, -2.8943]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0148,  0.8005],\n",
      "        [-0.5062,  0.8809]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.7476, -0.8080],\n",
      "        [-0.3801, -3.7009]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.8243,  2.6872],\n",
      "        [-0.0699,  0.6741]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.1115, -3.1063],\n",
      "        [-3.4424, -1.4489]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.9482, -0.1202],\n",
      "        [-0.1839, -1.3878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.7872, -3.1739],\n",
      "        [-2.5028, -2.5313]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.2266, 0.2703],\n",
      "        [0.2019, 1.2540]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3463, -2.6479],\n",
      "        [-1.1347, -2.8094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2995, -0.8706],\n",
      "        [-0.1702,  1.8622]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.7965, -4.0065],\n",
      "        [-2.2267, -1.7269]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3494,  0.6640],\n",
      "        [ 0.1044,  1.6483]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.5952, -2.2881],\n",
      "        [-2.6092, -1.0125]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5549,  1.9523],\n",
      "        [-1.2254,  1.2451]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5225, -2.2378],\n",
      "        [-2.7168, -2.0451]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2651,  0.0700],\n",
      "        [-0.0530,  0.4429]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8853, -2.1698],\n",
      "        [-2.0750, -2.6284]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1528,  1.7049],\n",
      "        [-0.2691,  0.8959]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.4631, -1.6687],\n",
      "        [-2.7692, -2.1698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2747,  1.1183],\n",
      "        [ 0.1025, -0.2072]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1481, -0.4487],\n",
      "        [-4.1779, -0.8522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1276,  3.0459],\n",
      "        [ 0.2515,  3.0503]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3955, -1.1263],\n",
      "        [-3.3788, -0.7994]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1612,  0.1325],\n",
      "        [ 0.0736, -0.4053]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3159, -1.2508],\n",
      "        [-3.2599, -0.9764]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0855,  0.3813],\n",
      "        [ 0.2356,  0.9677]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9703, -2.3061],\n",
      "        [-2.0710, -2.2104]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6523, -2.2161],\n",
      "        [-0.0434,  2.6696]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3905, -1.0912],\n",
      "        [-0.6411, -1.7515]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0549,  1.4905],\n",
      "        [-4.1914,  4.4655]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.7466, -1.4484],\n",
      "        [-2.9081, -2.4611]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3402,  1.1100],\n",
      "        [ 0.1448, -1.1344]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3434,  0.0371],\n",
      "        [-4.2405, -0.5645]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.8538,  0.5671],\n",
      "        [-0.0764,  0.9682]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0610, -1.3719],\n",
      "        [-4.3723, -1.3988]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0055,  0.7274],\n",
      "        [ 0.1078,  0.6559]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.9059, -1.1914],\n",
      "        [-3.2068, -0.8208]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1365,  0.5271],\n",
      "        [-0.1015,  0.1988]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3352, -1.7410],\n",
      "        [-4.0265, -1.5206]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.3723, 1.3426],\n",
      "        [0.2169, 0.3344]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8825, -1.1736],\n",
      "        [-4.1566, -2.7188]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3399, -0.5043],\n",
      "        [-0.5695,  0.9748]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.9515, -0.5879],\n",
      "        [-3.6738, -1.4661]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0030,  0.2685],\n",
      "        [-0.2838,  0.9588]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.9631, -2.1446],\n",
      "        [-3.8700,  1.4777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.4344,  1.0000],\n",
      "        [-0.8110, -2.2412]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9059, -2.9030],\n",
      "        [-3.7033, -2.1232]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2320,  2.4914],\n",
      "        [-0.2241,  1.1639]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.5103, -1.3761],\n",
      "        [-2.1593, -1.8207]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3187,  2.1530],\n",
      "        [-0.5608, -2.4372]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8751, -1.3445],\n",
      "        [-3.9474, -1.0337]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4263, -2.4300],\n",
      "        [-0.0062,  1.8172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6328, -1.3780],\n",
      "        [-2.6899, -1.8985]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0546,  1.1504],\n",
      "        [ 0.9826, -2.0049]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.7206, -1.1023],\n",
      "        [-3.2924, -2.2524]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.2453, 0.9824],\n",
      "        [0.4525, 1.4132]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6736, -3.1243],\n",
      "        [-3.9966, -1.8034]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4385,  0.2043],\n",
      "        [-0.2433,  1.9832]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5798, -2.7797],\n",
      "        [-3.4249, -2.7172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5878,  3.7136],\n",
      "        [-0.0358,  0.8231]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5345, -1.7256],\n",
      "        [-2.9705, -2.2689]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3174,  1.0740],\n",
      "        [ 0.1803,  1.3852]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.1481, -2.1502],\n",
      "        [-3.1246, -1.8280]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1396,  0.0306],\n",
      "        [-0.5961, -0.3094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.0933, -1.7043],\n",
      "        [-3.7826, -2.9549]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3699,  0.7729],\n",
      "        [-0.0708,  1.1797]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6259, -2.1984],\n",
      "        [-3.6883, -1.9558]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.3218, 1.1219],\n",
      "        [0.4698, 2.1101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.0514, -1.0647],\n",
      "        [-2.5225, -0.5101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3331, -0.1959],\n",
      "        [-0.3368,  1.6906]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.0770, -1.8062],\n",
      "        [-3.5666, -1.4195]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0035,  0.7872],\n",
      "        [-0.2754,  0.6975]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.4263, -2.3243],\n",
      "        [-4.3460, -3.1117]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3047, -1.5976],\n",
      "        [ 0.4076, -0.2729]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5975, -1.2231],\n",
      "        [-3.4279, -0.8296]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3672,  0.8257],\n",
      "        [ 0.3570, -0.1434]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.2291, -0.8150],\n",
      "        [-4.2186, -2.7763]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.4134,  2.6611],\n",
      "        [ 0.2813, -0.7616]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.5796, -1.6545],\n",
      "        [-4.6094, -1.1641]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2235, -1.2312],\n",
      "        [-0.2270,  1.3492]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6025, -2.0251],\n",
      "        [-3.4137, -2.0894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.6313,  0.7425],\n",
      "        [ 1.0261, -0.1143]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.4488, -1.4210],\n",
      "        [-3.2472,  1.6134]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0409, -0.6055],\n",
      "        [-2.7591,  3.3255]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8502, -3.2852],\n",
      "        [-3.8177, -1.6935]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4780, -1.8432],\n",
      "        [ 0.4153,  0.4124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.4861, -2.0905],\n",
      "        [-3.5472, -1.6286]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9567, 2.1591],\n",
      "        [0.4302, 0.8062]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5762, -2.5416],\n",
      "        [-3.6216, -2.2996]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2222, -0.6072],\n",
      "        [ 0.5406,  1.8328]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.6333, -1.4270],\n",
      "        [-3.8594, -2.1747]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3989,  1.5296],\n",
      "        [-0.4032,  2.5818]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0123, -2.9318],\n",
      "        [-3.9896, -2.0404]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9999, 0.1533],\n",
      "        [0.5092, 1.1321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.9709, -1.3947],\n",
      "        [-3.1907, -2.6650]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3496,  3.6393],\n",
      "        [-0.1908, -0.6544]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5869, -3.5773],\n",
      "        [-4.1699, -2.3930]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0539, 0.9132],\n",
      "        [0.8320, 2.9096]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.4945, -2.6349],\n",
      "        [-4.2667, -1.6650]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1679,  1.0611],\n",
      "        [-0.8218,  3.1139]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.8270, -2.1977],\n",
      "        [-5.4220, -2.3255]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0344,  2.0824],\n",
      "        [-0.2442,  1.6643]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.7099, -1.1101],\n",
      "        [-3.0485, -1.3923]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3923,  0.6569],\n",
      "        [-1.4237,  2.8933]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.7955, -2.3514],\n",
      "        [-3.9426, -1.9360]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.5120, 0.9077],\n",
      "        [0.5337, 1.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.7382, -2.4849],\n",
      "        [-4.0899, -2.1089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.3580, 2.3759],\n",
      "        [1.2648, 1.9669]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8259, -2.8171],\n",
      "        [-4.7123, -1.7176]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0524,  0.1941],\n",
      "        [ 0.3865,  0.8594]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5252, -2.8128],\n",
      "        [-3.5809, -2.2109]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.2017, 2.1691],\n",
      "        [0.0597, 1.2173]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.3563, -1.7762],\n",
      "        [-3.6218, -2.3578]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.8449, 2.0090],\n",
      "        [0.5134, 0.6375]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5931, -0.0419],\n",
      "        [-1.7491, -2.1606]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2231,  0.5125],\n",
      "        [-0.8901,  2.5982]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.6510, -3.3544],\n",
      "        [-3.7879, -3.4437]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1993,  0.1735],\n",
      "        [ 1.0163, -0.4965]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0684, -3.0256],\n",
      "        [-3.6047, -2.7007]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.0358,  0.0648],\n",
      "        [ 1.1100, -0.3025]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8573, -2.7227],\n",
      "        [-3.6277, -2.4615]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.1679, -0.8907],\n",
      "        [ 1.1656, -0.3903]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3487, -0.4151],\n",
      "        [-2.8105, -2.3714]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1843, -3.2581],\n",
      "        [ 0.9704, -1.0564]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3563, -2.9657],\n",
      "        [-3.6534, -2.7999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1863, 0.9887],\n",
      "        [0.9998, 0.2903]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5357, -5.0126],\n",
      "        [-1.6137, -2.8760]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.5231, 0.1897],\n",
      "        [0.0173, 1.2353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.6111, -3.1918],\n",
      "        [-2.4270, -3.1431]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.3044,  2.4050],\n",
      "        [ 0.6834, -0.0528]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9036, -3.5537],\n",
      "        [-2.7576, -3.2359]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4612, 2.7854],\n",
      "        [0.7405, 1.1154]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.5614,  0.9294],\n",
      "        [-1.7618, -3.6671]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.8629,  3.4944],\n",
      "        [ 1.1533,  0.3124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.2020, -2.4470],\n",
      "        [-2.7833, -3.8894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.0789,  0.7431],\n",
      "        [ 0.6351, -0.5047]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.4036, -3.0403],\n",
      "        [-2.9943, -3.0886]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.6516, 1.5177],\n",
      "        [0.8848, 1.1264]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.7345, -2.9635],\n",
      "        [-2.3594, -1.9816]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4945, 2.3784],\n",
      "        [0.5915, 1.3068]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8155, -1.8628],\n",
      "        [-2.8496, -3.1037]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3588, 1.6920],\n",
      "        [0.6462, 0.8670]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9718, -2.2532],\n",
      "        [-3.3292, -3.3811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4360, 2.0318],\n",
      "        [0.7835, 2.1346]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8290, -2.0277],\n",
      "        [-4.1646, -2.5730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3194, 1.9095],\n",
      "        [1.8090, 3.4066]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.4359, -2.6071],\n",
      "        [-2.9581, -1.4742]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7752, 1.4588],\n",
      "        [0.7950, 2.5778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.2167, -1.3809],\n",
      "        [-3.0809, -0.8918]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8509, 3.6168],\n",
      "        [0.8119, 2.4964]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8702, -1.7887],\n",
      "        [-3.1603, -1.8787]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.8352, 1.2883],\n",
      "        [1.1835, 2.0334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.7160, -2.1406],\n",
      "        [-3.8884, -1.9844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.8241, 1.8710],\n",
      "        [1.3559, 2.5013]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6415,  0.3065],\n",
      "        [-3.5493, -2.9299]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.7784,  2.9759],\n",
      "        [-2.1252,  2.9900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9722, -2.1364],\n",
      "        [-0.2484, -0.7822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.3950,  2.5282],\n",
      "        [-0.9261,  2.8545]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.1974, -1.7437],\n",
      "        [-3.2819, -1.8312]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2293, 3.1846],\n",
      "        [1.3347, 2.7089]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.7066, -0.9289],\n",
      "        [-3.0709, -0.5492]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.2955, -0.3878],\n",
      "        [ 0.1894,  2.6493]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5118, -1.0905],\n",
      "        [-4.4312, -3.3162]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.8239, 0.7479],\n",
      "        [0.9257, 2.5488]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3895, -1.8988],\n",
      "        [-3.4444, -2.1700]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4507, 2.4911],\n",
      "        [1.6054, 1.1196]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5089, -0.6896],\n",
      "        [-3.2481, -2.0405]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.9901,  2.5471],\n",
      "        [ 1.4152,  2.0269]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9483, -1.7316],\n",
      "        [-3.2220, -1.8124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2170, 2.6584],\n",
      "        [1.3104, 1.9676]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.9916, -2.2136],\n",
      "        [-2.6537, -1.1613]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8121, 1.2242],\n",
      "        [1.5858, 0.9739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8173, -2.4603],\n",
      "        [-2.7232, -1.4052]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8649, 2.9528],\n",
      "        [1.5835, 2.6185]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1414, -2.0937],\n",
      "        [-2.4254, -1.3485]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4155, 1.7601],\n",
      "        [1.7917, 2.5932]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9601, -3.0691],\n",
      "        [-2.6091,  0.5358]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.7348, 1.9982],\n",
      "        [1.1474, 0.6474]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3467, -1.0999],\n",
      "        [-2.1187, -2.2848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.6052, 2.3911],\n",
      "        [1.8907, 1.7495]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0513, -4.7945],\n",
      "        [-2.9002, -3.8334]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0648, 2.3131],\n",
      "        [2.0916, 2.9043]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.9647, -2.4605],\n",
      "        [-2.3349, -2.1321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3620, 1.9008],\n",
      "        [0.7593, 1.0494]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1926, -3.4126],\n",
      "        [-1.9329, -1.6662]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5122, 1.7137],\n",
      "        [1.5091, 2.2124]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.9316, -2.7533],\n",
      "        [-1.9267, -3.5904]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.7746, 1.6977],\n",
      "        [1.4650, 1.6329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.2775, -2.7214],\n",
      "        [-1.9100, -2.4738]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3789, 2.0621],\n",
      "        [1.3862, 0.4987]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.8600, -2.6932],\n",
      "        [-2.3095, -3.3099]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2184, 0.9518],\n",
      "        [1.6240, 1.4044]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3389, -2.8368],\n",
      "        [-1.5626, -2.6691]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.6598, 1.3018],\n",
      "        [1.2829, 1.3149]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.8527, -3.7153],\n",
      "        [-1.9750, -2.8704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5368, 2.0655],\n",
      "        [1.5889, 1.4285]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5466, -2.6638],\n",
      "        [-2.2844, -1.7045]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8841, 2.0613],\n",
      "        [1.1966, 2.8315]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1251, -1.7823],\n",
      "        [-2.3387, -2.6920]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5274, 1.6493],\n",
      "        [0.5237, 1.4095]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3562, -2.3431],\n",
      "        [-2.5411, -2.0807]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4984, 1.2861],\n",
      "        [2.0231, 1.8148]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3107, -2.0602],\n",
      "        [-3.2036, -2.3794]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3661, 1.6019],\n",
      "        [2.0024, 2.1987]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3162, -2.2945],\n",
      "        [-3.2149, -1.1095]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4485, 2.8834],\n",
      "        [1.2921, 2.6352]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9695, -0.6728],\n",
      "        [-3.4706, -0.7594]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1458, 1.7135],\n",
      "        [1.6903, 3.4716]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5033, -1.6011],\n",
      "        [-3.1443, -0.3894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7495, 1.7379],\n",
      "        [0.9211, 2.5983]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.1112, -0.3979],\n",
      "        [-3.6329,  0.2207]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.6781, 3.5507],\n",
      "        [1.1764, 3.6710]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.0700, -0.4077],\n",
      "        [-4.1471, -0.9907]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1986, 4.0126],\n",
      "        [1.1959, 3.5523]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.4681, -0.0078],\n",
      "        [-4.4117, -0.4396]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1690, 3.6139],\n",
      "        [1.2278, 3.9892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.5309, -2.0149],\n",
      "        [-4.5872, -0.4427]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7553, 2.4764],\n",
      "        [1.7001, 4.0634]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.1561,  0.5579],\n",
      "        [-4.2555,  0.1754]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0325, 3.7393],\n",
      "        [1.2661, 3.8330]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.1218,  0.0843],\n",
      "        [-4.4283,  0.0874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2609, 3.7587],\n",
      "        [1.4710, 2.9663]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.8994, -0.1917],\n",
      "        [-4.2591, -0.1470]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2490, 4.1501],\n",
      "        [1.2717, 3.6280]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.3008, -0.3797],\n",
      "        [-4.4927, -1.4806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2395, 3.4060],\n",
      "        [1.3016, 3.2679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5972, -0.3591],\n",
      "        [-3.5756, -0.3121]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2947, 4.0012],\n",
      "        [1.1386, 3.8203]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.2371, -0.2892],\n",
      "        [-3.5543, -0.5198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0159, 3.7135],\n",
      "        [1.0759, 3.9069]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0556, -0.9044],\n",
      "        [-3.6120, -0.8064]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0651, 3.6515],\n",
      "        [1.6620, 1.9755]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-4.1780, -1.1493],\n",
      "        [-3.2133, -1.1495]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.8439, 2.2901],\n",
      "        [1.1010, 3.4396]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9645, -0.9610],\n",
      "        [-2.6240, -1.1802]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1760, 3.0882],\n",
      "        [1.0257, 3.5207]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3029, -1.4376],\n",
      "        [-2.3782, -1.6679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.1712, 3.2364],\n",
      "        [1.0113, 3.4435]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.3375, -1.6262],\n",
      "        [-2.0318, -1.8233]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3413, 1.9410],\n",
      "        [1.2291, 3.1242]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.4137, -1.9344],\n",
      "        [-2.1280, -2.1613]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2425, 2.1297],\n",
      "        [0.9883, 2.6522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.0948, -1.9810],\n",
      "        [-1.6950, -1.9915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3714, 2.4856],\n",
      "        [1.1327, 2.7035]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5322, -2.1582],\n",
      "        [-1.5875, -2.3046]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8994, 1.5958],\n",
      "        [0.9707, 3.0376]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.5300, -2.2603],\n",
      "        [-1.7263, -1.9100]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0640, 2.5563],\n",
      "        [1.2275, 1.3685]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.5137, -1.8430],\n",
      "        [-2.0367, -0.9353]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5962, 2.6159],\n",
      "        [1.0172, 0.7520]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.5881, -2.6740],\n",
      "        [-1.4179, -2.8043]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2487, 2.6079],\n",
      "        [1.0558, 2.5327]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6935, -1.1617],\n",
      "        [-2.0237, -2.3361]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 1.0003, -0.2630],\n",
      "        [ 1.3305,  1.5693]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.1366, -2.6146],\n",
      "        [-1.1415, -2.7533]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.7074, 2.8256],\n",
      "        [0.5831, 2.2368]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.5108, -2.6477],\n",
      "        [-1.9868, -2.5108]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2936, 2.3877],\n",
      "        [1.3258, 1.4535]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.7653, -2.6492],\n",
      "        [-1.5274, -2.4008]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4191, 2.0827],\n",
      "        [1.4024, 1.8979]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9465, -2.5044],\n",
      "        [-1.6547, -2.0806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.7120, 1.4490],\n",
      "        [1.6657, 2.0644]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.8657, -1.8371],\n",
      "        [-1.7189, -1.9291]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.7046, 1.7410],\n",
      "        [1.5744, 1.9346]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5810, -1.7926],\n",
      "        [-1.7008, -1.6324]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.6503, 1.2242],\n",
      "        [1.8786, 1.5639]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.9463, -1.6645],\n",
      "        [-1.8616, -1.6414]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8397, 1.6609],\n",
      "        [1.8781, 1.6474]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1349, -1.0517],\n",
      "        [-1.7677, -1.1522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.2887, 1.0392],\n",
      "        [1.8215, 1.6761]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9145, -1.2392],\n",
      "        [-1.9425, -1.2104]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.5847, 1.3505],\n",
      "        [1.7780, 1.6466]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.2984, -0.7237],\n",
      "        [-2.4674, -0.7573]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.4037, 1.1427],\n",
      "        [1.9216, 1.0949]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.2185, -0.6417],\n",
      "        [-2.8706, -0.6688]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 2.3606,  1.3500],\n",
      "        [ 2.5669, -0.1976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.4042, -0.7061],\n",
      "        [-2.7945, -0.4057]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.1204, 1.1844],\n",
      "        [2.4964, 0.0928]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.4885, -0.3860],\n",
      "        [-2.5944, -0.5664]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.1356, 1.5843],\n",
      "        [2.3384, 1.4530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.1066, -0.6144],\n",
      "        [-3.2046, -0.4497]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.2383, 0.7935],\n",
      "        [2.2625, 1.4405]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.4276, -0.2955],\n",
      "        [-2.9954, -0.5080]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.2615, 1.3933],\n",
      "        [2.0646, 1.3390]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5265, -0.1680],\n",
      "        [-2.8387, -0.4553]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[2.2659, 1.4572],\n",
      "        [2.1616, 1.4145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.4117, -0.3651],\n",
      "        [-2.7112, -0.3939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.9386, 1.6584],\n",
      "        [2.3453, 1.5988]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1395, -0.2983],\n",
      "        [-2.1939, -0.3649]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.7140, 2.0256],\n",
      "        [1.7237, 1.7890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1596, -0.4884],\n",
      "        [-2.3734, -0.6247]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5619, 2.1790],\n",
      "        [1.7830, 2.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3396, -1.1397],\n",
      "        [-1.9699, -0.8591]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5164, 2.3706],\n",
      "        [1.5181, 2.3133]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3697, -1.0902],\n",
      "        [-3.7966, -1.2284]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.8989, 2.0321],\n",
      "        [2.0243, 1.9327]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1833, -1.2681],\n",
      "        [-2.1035, -1.1890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5413, 2.4330],\n",
      "        [1.5771, 2.2929]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.9190, -1.3008],\n",
      "        [-2.0012, -1.2732]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3400, 2.6052],\n",
      "        [1.4193, 2.6868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.3490, -1.6080],\n",
      "        [-2.2980, -1.8640]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5682, 2.3862],\n",
      "        [1.5887, 2.6999]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.9037, -1.3632],\n",
      "        [-1.9452, -1.3086]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2275, 2.7393],\n",
      "        [1.1688, 2.8373]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1061, -1.6684],\n",
      "        [-2.0645, -1.3041]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3410, 2.7735],\n",
      "        [1.4576, 2.5158]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.7893, -1.4394],\n",
      "        [-2.0969, -1.1490]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2584, 2.7615],\n",
      "        [1.5384, 2.4302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-1.8338, -1.1756],\n",
      "        [-2.3792, -1.7439]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.2366, 2.9948],\n",
      "        [1.1780, 2.9176]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.1854, -1.2039],\n",
      "        [-2.2927, -1.3256]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0935, 2.9542],\n",
      "        [1.1479, 2.8701]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5965, -1.2935],\n",
      "        [-2.6533, -1.3523]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3990, 2.3651],\n",
      "        [1.5470, 2.7847]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0479, -1.0787],\n",
      "        [-2.5214, -0.8562]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.4185, 2.9931],\n",
      "        [1.7237, 2.9951]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.1163, -1.3369],\n",
      "        [-3.3725, -1.0658]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3663, 3.1781],\n",
      "        [1.3938, 2.5559]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.5804, -1.4246],\n",
      "        [-3.4009, -0.9278]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5282, 2.8120],\n",
      "        [1.0567, 2.7113]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.6087, -1.0368],\n",
      "        [-2.6415, -1.1975]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.9076, 3.4321],\n",
      "        [1.1996, 3.2784]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.9601, -1.2051],\n",
      "        [-2.3703, -0.8072]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.5016, 3.5399],\n",
      "        [0.7796, 3.5417]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5453, -1.3193],\n",
      "        [-2.9458, -1.6131]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0243, 3.6164],\n",
      "        [1.0138, 3.3011]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m ci \u001b[38;5;241m=\u001b[39m CausalImageModelWrapper(batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, g_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, Q_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlight_or_dark\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprice_ave\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutcome\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m, in \u001b[0;36mCausalImageModelWrapper.train\u001b[0;34m(self, images, confounds, treatments, outcomes, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m g, Q0, Q1, g_loss, Q_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images, confounds, treatments, outcomes)\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m g_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (Q_loss)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "ci = CausalImageModelWrapper(batch_size = 2, g_weight=0.1, Q_weight=0.1)\n",
    "ci.train(df[\"img_path\"],df[\"light_or_dark\"], df[\"price_ave\"], df[\"outcome\"],epochs = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29585/1594774515.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ci.model.load_state_dict(torch.load(\"\"))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ci \u001b[38;5;241m=\u001b[39m CausalImageModelWrapper(batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, g_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, Q_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# To load the model weights later\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m ci\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "# Save the model weights\n",
    "#torch.save(ci.model.state_dict(), \"causal_image_model_weights.pth\")\n",
    "ci = CausalImageModelWrapper(batch_size = 32, g_weight=0.1, Q_weight=0.1)\n",
    "# To load the model weights later\n",
    "ci.model.load_state_dict(torch.load(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:27<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "probs,preds,Ys = ci.inference(df[\"img_path\"], df[\"light_or_dark\"],df[\"outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5111, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74277663, 0.85142642],\n",
       "       [0.40638188, 0.73140544],\n",
       "       [0.95202929, 0.91336769],\n",
       "       ...,\n",
       "       [0.08029114, 0.85897499],\n",
       "       [0.4180325 , 0.94808537],\n",
       "       [0.91433805, 0.96427166]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48444531402856583\n",
      "Precision: 0.7009531374106434\n",
      "Recall: 0.4839594187003016\n",
      "F1 Score: 0.5725871857258719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(Ys, preds)\n",
    "precision = precision_score(Ys, preds)\n",
    "recall = recall_score(Ys, preds)\n",
    "f1 = f1_score(Ys, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:27<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: [0.75747448 0.75430137 0.76178122 ... 0.73347253 0.77003992 0.74702567] Q1: [0.67066425 0.65308595 0.68395323 ... 0.66646349 0.68307447 0.66885483]\n",
      "0.07425691153707628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(ci.ATE(df[\"light_or_dark\"], df[\"img_path\"],Y = None,platt_scaling = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE_unadjusted:  0.10267981830743678\n",
      "0.07905631183025796 0.11232609131180016\n",
      "defaultdict(<class 'list'>, {(1, 1): [1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1], (1, 0): [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1], (0, 0): [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1], (0, 1): [1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0]})\n",
      "ATE_adjusted:  0.09569120157102906\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "def ATE_unadjusted(T, Y):\n",
    "    x = defaultdict(list)\n",
    "    for t, y in zip(T, Y):\n",
    "        x[t].append(y)\n",
    "    T0 = np.mean(x[0])\n",
    "    T1 = np.mean(x[1])\n",
    "    return T0 - T1\n",
    "\n",
    "def ATE_adjusted(C, T, Y):\n",
    "    x = defaultdict(list)\n",
    "    for c, t, y in zip(C, T, Y):\n",
    "        x[c, t].append(y)\n",
    "\n",
    "    C0_ATE = np.mean(x[0,0]) - np.mean(x[0,1])\n",
    "    C1_ATE = np.mean(x[1,0]) - np.mean(x[1,1])\n",
    "    print(C0_ATE, C1_ATE)\n",
    "    print(x)\n",
    "    return np.mean([C0_ATE, C1_ATE])\n",
    "\n",
    "\n",
    "print(\"ATE_unadjusted: \", ATE_unadjusted(df[\"price_ave\"], df[\"outcome\"]))\n",
    "print(\"ATE_adjusted: \", ATE_adjusted(df[\"light_or_dark\"], df[\"price_ave\"],df[\"outcome\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
