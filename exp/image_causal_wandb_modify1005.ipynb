{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler,SequentialSampler\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logit\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wandbの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = (torch.cuda.device_count() > 0)\n",
    "MASK_IDX = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def platt_scale(outcome,probs):\n",
    "    logits = logit(probs)\n",
    "    logits = logits.reshape(-1,1)\n",
    "    log_reg = LogisticRegression(penalty='none', warm_start = True, solver = 'lbfgs' )\n",
    "    log_reg.fit(logits, outcome)\n",
    "    return log_reg.predict_proba(logits)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1.0 + torch.erf(x/math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confound_vector(ids, vocab_size, use_counts = False):\n",
    "    vec = torch.zeros(ids.shape[0],vocab_size)\n",
    "    ones = torch.ones_like(ids,dtype = torch.float)\n",
    "    \n",
    "    if CUDA:\n",
    "        vec = vec.cuda()\n",
    "        ones = ones.cuda()\n",
    "        ids = ids.cuda()\n",
    "    vec[:,1] = 0.0\n",
    "    if not use_counts:\n",
    "        vec = (vec != 0).float()\n",
    "    return vec.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ImageCausalModel(nn.Module):\n",
    "    \"\"\"The model itself.\"\"\"\n",
    "    def __init__(self, num_labels = 2,pretrained_model_names = \"timm/eva02_base_patch14_224.mim_in22k\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.base_model = timm.create_model(pretrained_model_names,pretrained = True,num_classes = 0)\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # 因果推論用の追加レイヤー ここいらない説\n",
    "        #self.classifier = nn.Linear(self.base_model.num_features, num_labels)\n",
    "        self.Q_cls = nn.ModuleDict()\n",
    "\n",
    "        # self.base_model.num_features は、事前学習済みの画像モデルからの特徴量サイズです。\n",
    "        input_size = self.base_model.num_features + self.num_labels\n",
    "        print(self.base_model.num_features)\n",
    "        print(input_size)\n",
    "        for T in range(2):\n",
    "            # ModuleDict keys have to be strings..\n",
    "            self.Q_cls['%d' % T] = nn.Sequential(\n",
    "                nn.Linear(input_size, 200),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(200, self.num_labels))\n",
    "        \n",
    "\n",
    "        self.g_cls = nn.Linear(self.base_model.num_features + self.num_labels, \n",
    "            self.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self,images, confounds, treatment=None, outcome = None):\n",
    "        features = self.base_model(images)\n",
    "        # print(\"features\")\n",
    "        # print(\"C\", confounds.shape)\n",
    "        # print(confounds)\n",
    "        # print(confounds.unsqueeze(1).shape)\n",
    "        C = make_confound_vector(confounds.unsqueeze(1), self.num_labels)\n",
    "        inputs = torch.cat((features, C), dim =  1)\n",
    "        g = self.g_cls(inputs)\n",
    "\n",
    "        if outcome is not None:\n",
    "            g_loss = CrossEntropyLoss()(g.view(-1, self.num_labels),treatment.view(-1))\n",
    "        else:\n",
    "            g_loss = 0.0\n",
    "\n",
    "        Q_logits_T0 = self.Q_cls['0'](inputs)\n",
    "        Q_logits_T1 = self.Q_cls['1'](inputs)\n",
    "\n",
    "        #[todo] ここ元論文と実装が異なってたなぜ?\n",
    "        #Q_prob_T0 = torch.sigmoid(Q_logits_T0)\n",
    "        #Q_prob_T1 = torch.sigmoid(Q_logits_T1)\n",
    "        if outcome is not None:\n",
    "            T0_indices = (treatment == 0).nonzero().squeeze()\n",
    "            Y_T1_labels = outcome.clone().scatter(0,T0_indices, -100)\n",
    "\n",
    "            T1_indices = (treatment == 1).nonzero().squeeze()\n",
    "            Y_T0_labels = outcome.clone().scatter(0,T1_indices, -100)\n",
    "            Q_loss_T1 = CrossEntropyLoss()(Q_logits_T1.view(-1,self.num_labels), Y_T1_labels)\n",
    "            Q_loss_T0 = CrossEntropyLoss()(Q_logits_T0.view(-1, self.num_labels), Y_T0_labels)\n",
    "            Q_loss = Q_loss_T1 + Q_loss_T0\n",
    "        else:\n",
    "            Q_loss = 0.0\n",
    "            \n",
    "        sm = torch.nn.Softmax(dim = 1)\n",
    "        Q_prob_T0 = sm(Q_logits_T0)[:,1]\n",
    "        Q_prob_T1 = sm(Q_logits_T1)[:,1]\n",
    "        g_prob = sm(g)[:,1]\n",
    "    \n",
    "        \n",
    "        return g_prob, Q_prob_T0, Q_prob_T1, g_loss, Q_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CausalImageModelWrapper:\n",
    "    def __init__(self, g_weight=1.0, Q_weight=0.1, mlm_weight=1.0, batch_size=32):\n",
    "        self.model = ImageCausalModel(num_labels=2, pretrained_model_names=\"timm/eva02_tiny_patch14_224.mim_in22k\")\n",
    "        if CUDA:\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "        self.loss_weights = {\n",
    "            'g': g_weight,\n",
    "            'Q': Q_weight\n",
    "        }\n",
    "        self.batch_size = batch_size\n",
    "        self.losses = []\n",
    "\n",
    "    def train(self,images, confounds, treatments, outcomes , learning_rate = 2e-5, epochs  = 3):\n",
    "\n",
    "        wandb.init(project = \"image_causal_project\", config = {\n",
    "            \"learning_rate\":learning_rate,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"g_weight\": self.loss_weights['g'],\n",
    "            \"Q_weight\": self.loss_weights['Q']\n",
    "        })\n",
    "\n",
    "        dataloader = self.build_dataloader(images, confounds, treatments, outcomes, batch_size = self.batch_size)\n",
    "        self.model.train()\n",
    "        optimizer = AdamW(self.model.parameters(), lr = learning_rate, eps = 1e-8)\n",
    "        total_steps = len(dataloader) * epochs\n",
    "        warmup_steps = total_steps * 0.1\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = warmup_steps,num_training_steps = total_steps)\n",
    "        print(total_steps)\n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "            g_losses = []\n",
    "            Q_losses = []\n",
    "            self.model.train()\n",
    "            for batch in dataloader:\n",
    "                if CUDA:\n",
    "                    batch = tuple(x.cuda() for x in batch)\n",
    "                images, confounds, treatments, outcomes = batch\n",
    "\n",
    "                self.model.zero_grad()\n",
    "                g, Q0, Q1, g_loss, Q_loss = self.model(images, confounds, treatments, outcomes)\n",
    "                loss = self.loss_weights['g'] * g_loss + self.loss_weights['Q'] * (Q_loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                g_losses.append(g_loss.detach().cpu().item())\n",
    "                Q_losses.append((Q_loss).detach().cpu().item())\n",
    "                epoch_losses.append(loss.detach().cpu().item())\n",
    "            \n",
    "            avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            avg_g_loss = sum(g_losses) / len(g_losses)\n",
    "            avg_Q_loss = sum(Q_losses) / len(Q_losses)\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch, \n",
    "                \"loss\":avg_loss, \n",
    "                \"g_losses\":avg_g_loss, \n",
    "                \"Q_losses\" : avg_Q_loss\n",
    "                })\n",
    "        wandb.watch(self.model)\n",
    "        wandb.finish()            \n",
    "        return self.model\n",
    "    \n",
    "    def inference(self, images, confounds, outcome = None):\n",
    "        self.model.eval()\n",
    "        dataloader = self.build_dataloader(images, confounds,outcomes = outcome,\n",
    "                                           sampler = 'sequential',batch_size= self.batch_size)\n",
    "        Q0s = []\n",
    "        Q1s = []\n",
    "        Ys = []\n",
    "        for i, batch in tqdm(enumerate(dataloader),total = len(dataloader)):\n",
    "            if CUDA: \n",
    "                batch = (x.cuda() for x in batch)\n",
    "            images, confounds, _ ,outcomes = batch\n",
    "\n",
    "            g, Q0,Q1,_,_= self.model(images, confounds, outcome = None)\n",
    "    \n",
    "            Q0s += Q0.detach().cpu().numpy().tolist()\n",
    "            Q1s += Q1.detach().cpu().numpy().tolist()\n",
    "            Ys += outcomes.detach().cpu().numpy().tolist()\n",
    "\n",
    "            ## [todo] inferenceメソッドの形式?\n",
    "        probs = np.array(list(zip(Q0s, Q1s)))\n",
    "        preds = np.argmax(probs, axis = 1)  \n",
    "        return probs, preds, Ys\n",
    "    \n",
    "    def ATE(self,C,image, Y = None, platt_scaling = False):\n",
    "        ## [todo] ATEの計算方法\n",
    "        Q_probs,_,Ys = self.inference(image,C,outcome = Y)\n",
    "        if platt_scaling and Y is not None:\n",
    "            Q0 = platt_scale(Ys, Q_probs[:,0])[:,0]\n",
    "            Q1 = platt_scale(Ys, Q_probs[:,1])[:,1]\n",
    "        else:\n",
    "            Q0 = Q_probs[:,0]\n",
    "            Q1 = Q_probs[:,1]\n",
    "        \n",
    "        print(\"Q0:\", Q0, \"Q1:\", Q1)\n",
    "        return np.mean(Q0 - Q1)\n",
    "\n",
    "    def build_dataloader(self,image_paths, confounds, treatments = None, outcomes = None,batch_size = 32,sampler = \"random\"):\n",
    "        dataset = CausalImageDataset(image_paths, confounds, treatments, outcomes)\n",
    "        sampler = RandomSampler(dataset) if sampler == \"random\" else SequentialSampler(dataset)\n",
    "        dataloader = DataLoader(dataset, batch_size = batch_size,sampler = sampler)\n",
    "        return dataloader\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalImageDataset(Dataset):\n",
    "    def __init__(self,image_paths, confounds, treatments = None, outcomes = None,transform = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.confounds = confounds\n",
    "        self.treatments = treatments\n",
    "        self.outcomes = outcomes\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406] , std = [0.229, 0.224, 0.225])\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        confounds = self.confounds[idx]\n",
    "        treatment = self.treatments[idx] if self.treatments is not None else -1\n",
    "        outcome = self.outcomes[idx] if self.outcomes is not None else -1\n",
    "        return image , confounds, treatment, outcome\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\")\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/outputs_v4.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"light_or_dark\"] = df[\"light_or_dark\"].apply(lambda x : 1 if x == \"light\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "ci = CausalImageModelWrapper(batch_size = 2, g_weight=0.1, Q_weight=0.1)\n",
    "ci.train(df[\"img_path\"],df[\"light_or_dark\"], df[\"price_ave\"], df[\"outcome\"],epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "#torch.save(ci.model.state_dict(), \"causal_image_model_weights.pth\")\n",
    "ci = CausalImageModelWrapper(batch_size = 32, g_weight=0.1, Q_weight=0.1)\n",
    "# To load the model weights later\n",
    "ci.model.load_state_dict(torch.load(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ci.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs,preds,Ys = ci.inference(df[\"img_path\"], df[\"light_or_dark\"],df[\"outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(Ys, preds)\n",
    "precision = precision_score(Ys, preds)\n",
    "recall = recall_score(Ys, preds)\n",
    "f1 = f1_score(Ys, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ci.ATE(df[\"light_or_dark\"], df[\"img_path\"],Y = None,platt_scaling = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "def ATE_unadjusted(T, Y):\n",
    "    x = defaultdict(list)\n",
    "    for t, y in zip(T, Y):\n",
    "        x[t].append(y)\n",
    "    T0 = np.mean(x[0])\n",
    "    T1 = np.mean(x[1])\n",
    "    return T0 - T1\n",
    "\n",
    "def ATE_adjusted(C, T, Y):\n",
    "    x = defaultdict(list)\n",
    "    for c, t, y in zip(C, T, Y):\n",
    "        x[c, t].append(y)\n",
    "\n",
    "    C0_ATE = np.mean(x[0,0]) - np.mean(x[0,1])\n",
    "    C1_ATE = np.mean(x[1,0]) - np.mean(x[1,1])\n",
    "    print(C0_ATE, C1_ATE)\n",
    "    print(x)\n",
    "    return np.mean([C0_ATE, C1_ATE])\n",
    "\n",
    "\n",
    "print(\"ATE_unadjusted: \", ATE_unadjusted(df[\"price_ave\"], df[\"outcome\"]))\n",
    "print(\"ATE_adjusted: \", ATE_adjusted(df[\"light_or_dark\"], df[\"price_ave\"],df[\"outcome\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
